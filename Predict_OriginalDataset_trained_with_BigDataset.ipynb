{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear directorio para guardar los gr√°ficos\n",
    "os.makedirs('hyperParams2Balanced_2apply2OriginalDataset_plots', exist_ok=True)\n",
    "\n",
    "# Archivo para guardar las salidas de texto\n",
    "output_file = open('hyperParams2Balanced_2apply2OriginalDataset.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/lianbaguebatlle/.cache/kagglehub/datasets/snap/amazon-fine-food-reviews/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"snap/amazon-fine-food-reviews\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   ProductId          UserId                      ProfileName  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       1      5  1303862400   \n",
      "1                     0                       0      1  1346976000   \n",
      "2                     1                       1      4  1219017600   \n",
      "3                     3                       3      2  1307923200   \n",
      "4                     0                       0      5  1350777600   \n",
      "\n",
      "                 Summary                                               Text  \n",
      "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
      "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
      "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
      "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
      "4            Great taffy  Great taffy at a great price.  There was a wid...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the full path to the dataset CSV file\n",
    "csv_file_path = f\"{path}/Reviews.csv\"\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "dfBig = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(dfBig.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Score                                               Text\n",
       "0   1      5  I have bought several of the Vitality canned d...\n",
       "1   2      1  Product arrived labeled as Jumbo Salted Peanut...\n",
       "2   3      4  This is a confection that has been around a fe...\n",
       "3   4      2  If you are looking for the secret ingredient i...\n",
       "4   5      5  Great taffy at a great price.  There was a wid..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quitamos columnas innecesarias de nuevo\n",
    "dfSimple = dfBig.drop(columns=['ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time', 'Summary'])\n",
    "dfSimple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lianbaguebatlle/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/lianbaguebatlle/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"WITHOUT LEMMATIZATION\"\"\"\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# NLTK resources\n",
    "nltk.download('stopwords') #Llista de stopwords + comunes\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Split text into words\n",
    "    words = text.split()\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Join words back into a single string\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lianbaguebatlle/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/lianbaguebatlle/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords') #Llista de stopwords + comunes\n",
    "nltk.download('punkt')\n",
    "\n",
    "def clean_text(text):\n",
    "    # Initialize the lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Split text into words\n",
    "    words = text.split()\n",
    "    # Remove stopwords and apply lemmatization\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    # Join words back into a single string\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>product arrived labeled jumbo salted peanutsth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Score                                               Text\n",
       "0   1      5  bought several vitality canned dog food produc...\n",
       "1   2      1  product arrived labeled jumbo salted peanutsth...\n",
       "2   3      4  confection around centuries light pillowy citr...\n",
       "3   4      2  looking secret ingredient robitussin believe f...\n",
       "4   5      5  great taffy great price wide assortment yummy ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacemos las mismas limpiezas que antes\n",
    "dfSimple.dropna(subset=[\"Text\"], inplace=True)\n",
    "dfSimple['Text'] = dfSimple['Text'].apply(clean_text)\n",
    "dfSimple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>product arrived labeled jumbo salted peanutsth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Score                                               Text\n",
       "0   1      1  bought several vitality canned dog food produc...\n",
       "1   2      0  product arrived labeled jumbo salted peanutsth...\n",
       "2   3      1  confection around centuries light pillowy citr...\n",
       "3   4      0  looking secret ingredient robitussin believe f...\n",
       "4   5      1  great taffy great price wide assortment yummy ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBigBinary = dfSimple.copy()\n",
    "dfBigBinary['Score'] = dfBigBinary['Score'].apply(lambda x: 1 if x > 2.5 else 0)\n",
    "dfBigBinary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A PARTIR D'AQUI ES LO DE BALANCED\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(dfBigBinary['Text'])\n",
    "y = dfBigBinary['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un conjunto de datos balanceado\n",
    "df_positive = dfBigBinary[dfBigBinary['Score'] == 1]\n",
    "df_negative = dfBigBinary[dfBigBinary['Score'] == 0]\n",
    "df_balanced = pd.concat([df_positive.sample(len(df_negative), random_state=42), df_negative])\n",
    "\n",
    "X_balanced = tfidf.transform(df_balanced['Text'])\n",
    "y_balanced = df_balanced['Score']\n",
    "\n",
    "# Divisi√≥n de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 131259\n",
      "Test Set Size: 32815\n",
      "\n",
      "Training Set Class Distribution:\n",
      "Positives (overall = 1): 50.10%\n",
      "Negatives (overall = 0): 49.90%\n",
      "\n",
      "Test Set Class Distribution:\n",
      "Positives (overall = 1): 49.59%\n",
      "Negatives (overall = 0): 50.41%\n"
     ]
    }
   ],
   "source": [
    "# Print sizes of training and test sets\n",
    "print(f\"Training Set Size: {X_train.shape[0]}\")\n",
    "print(f\"Test Set Size: {X_test.shape[0]}\")\n",
    "\n",
    "# Calculate and print class distributions\n",
    "train_positive_percentage = (y_train[y_train == 1].count() / y_train.shape[0]) * 100\n",
    "train_negative_percentage = (y_train[y_train == 0].count() / y_train.shape[0]) * 100\n",
    "\n",
    "test_positive_percentage = (y_test[y_test == 1].count() / y_test.shape[0]) * 100\n",
    "test_negative_percentage = (y_test[y_test == 0].count() / y_test.shape[0]) * 100\n",
    "\n",
    "print(\"\\nTraining Set Class Distribution:\")\n",
    "print(f\"Positives (overall = 1): {train_positive_percentage:.2f}%\")\n",
    "print(f\"Negatives (overall = 0): {train_negative_percentage:.2f}%\")\n",
    "\n",
    "print(\"\\nTest Set Class Distribution:\")\n",
    "print(f\"Positives (overall = 1): {test_positive_percentage:.2f}%\")\n",
    "print(f\"Negatives (overall = 0): {test_negative_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los hiperpar√°metros a buscar para cada modelo\n",
    "param_grid = {\n",
    "    \"Logistic Regression\": {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'solver': ['newton-cg', 'lbfgs']\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'criterion': ['gini']\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    \"K-Nearest Neighbors\": {\n",
    "        'n_neighbors': [3, 5],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean']\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear los modelos base\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    #\"Naive Bayes (Multinomial)\": MultinomialNB(),\n",
    "    #\"Naive Bayes (Bernoulli)\": BernoulliNB(),\n",
    "    #\"Naive Bayes (Gaussian)\": GaussianNB(),\n",
    "    # \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    # \"SVM\": SVC(probability=True),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando mejores hiperpar√°metros para: Logistic Regression\n",
      "\n",
      "Buscando mejores hiperpar√°metros para: Random Forest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lianbaguebatlle/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "18 fits failed out of a total of 36.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lianbaguebatlle/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/lianbaguebatlle/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/lianbaguebatlle/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/lianbaguebatlle/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lianbaguebatlle/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/lianbaguebatlle/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/lianbaguebatlle/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/lianbaguebatlle/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/lianbaguebatlle/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.86986035 0.87306013        nan        nan\n",
      " 0.79450552 0.80074509        nan        nan 0.8218865  0.82528436]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando mejores hiperpar√°metros para: K-Nearest Neighbors\n",
      "\n",
      "Buscando mejores hiperpar√°metros para: Gradient Boosting\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Buscar los mejores hiperpar√°metros\n",
    "best_params = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Buscando mejores hiperpar√°metros para: {model_name}\\n\")\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid[model_name], cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params[model_name] = grid_search.best_params_\n",
    "output_file.write(f\"{best_params}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelos con los mejores hiperpar√°metros\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, **best_params[\"Logistic Regression\"]),\n",
    "    \"Random Forest\": RandomForestClassifier(**best_params[\"Random Forest\"]),\n",
    "    \"Naive Bayes (Multinomial)\": MultinomialNB(),\n",
    "    \"Naive Bayes (Bernoulli)\": BernoulliNB(),\n",
    "    #\"Naive Bayes (Gaussian)\": GaussianNB(),\n",
    "    #\"Decision Tree\": DecisionTreeClassifier(),\n",
    "    #\"SVM\": SVC(probability=True, **best_params[\"SVM\"]),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(**best_params[\"K-Nearest Neighbors\"]),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(**best_params[\"Gradient Boosting\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para almacenar los resultados despu√©s del ajuste de hiperpar√°metros\n",
    "results_after = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    output_file.write(f\"Entrenando modelo con mejores hiperpar√°metros: {model_name}\\n\")\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    # Predecir en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    # Evaluar el rendimiento\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # Guardar los resultados\n",
    "    results_after[model_name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"FPR\": fpr,\n",
    "        \"TPR\": tpr\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSimpleBinary = pd.read_csv('amazon_reviews_SimpleBinary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>purchased device worked advertised never much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>works expected sprung higher capacity think ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>think worked greathad diff bran gb card went s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>bought retail packaging arrived legit orange e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  overall                                         reviewText\n",
       "0           0        1                                             issues\n",
       "1           1        1  purchased device worked advertised never much ...\n",
       "2           2        1  works expected sprung higher capacity think ma...\n",
       "3           3        1  think worked greathad diff bran gb card went s...\n",
       "4           4        1  bought retail packaging arrived legit orange e..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSimpleBinary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Limit to 5000 features for simplicity\n",
    "X_SimpleBinary = tfidf.fit_transform(dfSimpleBinary['reviewText'])  \n",
    "\n",
    "# y = Etiqueta\n",
    "y_SimpleBinary = dfSimpleBinary['overall']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados en el dataset dfSimple:\n"
     ]
    }
   ],
   "source": [
    "output_file.write(\"\\nResultados en el dataset dfSimpleBinary:\\n\")\n",
    "print(\"\\nResultados en el dataset dfSimple:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando modelo: Logistic Regression\n",
      "Logistic Regression prediction distribution:\n",
      "0    2688\n",
      "1    2226\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.4375, Precision: 0.9102, Recall: 0.4414, F1 Score: 0.5945\n",
      "Aplicando modelo: Random Forest\n",
      "Random Forest prediction distribution:\n",
      "1    3683\n",
      "0    1231\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.7352, Precision: 0.9465, Recall: 0.7595, F1 Score: 0.8427\n",
      "Aplicando modelo: Naive Bayes (Multinomial)\n",
      "Naive Bayes (Multinomial) prediction distribution:\n",
      "1    2969\n",
      "0    1945\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.5818, Precision: 0.9269, Recall: 0.5996, F1 Score: 0.7281\n",
      "Aplicando modelo: Naive Bayes (Bernoulli)\n",
      "Naive Bayes (Bernoulli) prediction distribution:\n",
      "1    3541\n",
      "0    1373\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.6925, Precision: 0.9348, Recall: 0.7211, F1 Score: 0.8142\n",
      "Aplicando modelo: K-Nearest Neighbors\n",
      "K-Nearest Neighbors prediction distribution:\n",
      "1    4908\n",
      "0       6\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.9328, Precision: 0.9340, Recall: 0.9987, F1 Score: 0.9653\n",
      "Aplicando modelo: Gradient Boosting\n",
      "Gradient Boosting prediction distribution:\n",
      "0    4615\n",
      "1     299\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.1129, Precision: 0.8863, Recall: 0.0577, F1 Score: 0.1084\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Aplicando modelo: {model_name}\")\n",
    "    output_file.write(f\"Aplicando modelo: {model_name}\\n\")\n",
    "    \n",
    "    # Predict labels and probabilities\n",
    "    y_pred_new = model.predict(X_SimpleBinary)\n",
    "    print(f\"{model_name} prediction distribution:\")\n",
    "    print(pd.Series(y_pred_new).value_counts())\n",
    "\n",
    "    y_pred_prob_new = model.predict_proba(X_SimpleBinary)[:, 1]\n",
    "    \n",
    "    # If labels are available, evaluate performance\n",
    "    accuracy = accuracy_score(y_SimpleBinary, y_pred_new)\n",
    "    precision = precision_score(y_SimpleBinary, y_pred_new, average='binary')\n",
    "    recall = recall_score(y_SimpleBinary, y_pred_new, average='binary')\n",
    "    f1 = f1_score(y_SimpleBinary, y_pred_new, average='binary')\n",
    "    output_file.write(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\\n\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    results[model_name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"FPR\": fpr,\n",
    "        \"TPR\": tpr\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALE MAL, PROVO NOMES AMB RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters from Grid Search\n",
    "best_random_forest_params = {\n",
    "    'criterion': 'gini',\n",
    "    'max_depth': None,\n",
    "    'max_features': 'sqrt',\n",
    "    'n_estimators': 100\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model with the best hyperparameters\n",
    "random_forest = RandomForestClassifier(**best_random_forest_params, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "Prediction distribution:\n",
      "0    16449\n",
      "1    16366\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Train the Random Forest model\n",
    "print(\"Training Random Forest...\")\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "print(f\"Prediction distribution:\")\n",
    "print(pd.Series(y_pred).value_counts())\n",
    "\n",
    "y_pred_prob = random_forest.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Evaluation:\n",
      "Accuracy: 0.8831\n",
      "Precision: 0.8822\n",
      "Recall: 0.8820\n",
      "F1 Score: 0.8821\n",
      "ROC AUC: 0.9561\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='binary')\n",
    "recall = recall_score(y_test, y_pred, average='binary')\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Random Forest Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting prediction distribution:\n",
      "1    3588\n",
      "0    1326\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_pred_new = random_forest.predict(X_SimpleBinary)\n",
    "print(f\"{model_name} prediction distribution:\")\n",
    "print(pd.Series(y_pred_new).value_counts())\n",
    "y_pred_prob_new = random_forest.predict_proba(X_SimpleBinary)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Evaluation on dfSimpleBinary:\n",
      "Accuracy: 0.7200\n",
      "Precision: 0.9479\n",
      "Recall: 0.7410\n",
      "F1 Score: 0.8317\n",
      "ROC AUC: 0.6282\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model Performance on New Dataset\n",
    "accuracy_new = accuracy_score(y_SimpleBinary, y_pred_new)\n",
    "precision_new = precision_score(y_SimpleBinary, y_pred_new)\n",
    "recall_new = recall_score(y_SimpleBinary, y_pred_new)\n",
    "f1_new = f1_score(y_SimpleBinary, y_pred_new)\n",
    "fpr_new, tpr_new, _ = roc_curve(y_SimpleBinary, y_pred_prob_new)\n",
    "roc_auc_new = auc(fpr_new, tpr_new)\n",
    "\n",
    "# Print Evaluation Metrics\n",
    "print(\"\\nRandom Forest Evaluation on dfSimpleBinary:\")\n",
    "print(f\"Accuracy: {accuracy_new:.4f}\")\n",
    "print(f\"Precision: {precision_new:.4f}\")\n",
    "print(f\"Recall: {recall_new:.4f}\")\n",
    "print(f\"F1 Score: {f1_new:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_new:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
