Resultados para Logistic Regression:
Accuracy: 0.8923
Precision: 0.9104
Recall: 0.8841
F1 Score: 0.8971
ROC AUC: 0.9375

Resultados para Random Forest:
Accuracy: 0.8538
Precision: 0.8906
Recall: 0.8261
F1 Score: 0.8571
ROC AUC: 0.9092

Resultados para Naive Bayes (Multinomial):
Accuracy: 0.8077
Precision: 0.9783
Recall: 0.6522
F1 Score: 0.7826
ROC AUC: 0.9575

Resultados para Naive Bayes (Bernoulli):
Accuracy: 0.8308
Precision: 0.7831
Recall: 0.9420
F1 Score: 0.8553
ROC AUC: 0.9332

Resultados para Naive Bayes (Gaussian):
Accuracy: 0.6538
Precision: 0.8529
Recall: 0.4203
F1 Score: 0.5631
ROC AUC: 0.6692

Resultados para Decision Tree:
Accuracy: 0.7615
Precision: 0.7500
Recall: 0.8261
F1 Score: 0.7862
ROC AUC: 0.7573

Resultados para SVM:
Accuracy: 0.8769
Precision: 0.8841
Recall: 0.8841
F1 Score: 0.8841
ROC AUC: 0.9373

Resultados para K-Nearest Neighbors:
Accuracy: 0.8231
Precision: 0.8966
Recall: 0.7536
F1 Score: 0.8189
ROC AUC: 0.9062

Resultados para Gradient Boosting:
Accuracy: 0.8231
Precision: 0.8382
Recall: 0.8261
F1 Score: 0.8321
ROC AUC: 0.8888

Mejores hiperparámetros para LogisticRegression: {'C': 10, 'solver': 'liblinear'}
Mejores hiperparámetros para RandomForestClassifier: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 50}
Mejores hiperparámetros para MultinomialNB: {'alpha': 0.1}
Mejores hiperparámetros para BernoulliNB: {'alpha': 0.1}
Mejores hiperparámetros para DecisionTreeClassifier: {'max_depth': 20, 'min_samples_split': 20}
Mejores hiperparámetros para SVC: {'C': 10, 'kernel': 'rbf'}
Mejores hiperparámetros para KNeighborsClassifier: {'n_neighbors': 3, 'weights': 'uniform'}
Mejores hiperparámetros para GradientBoostingClassifier: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100}
