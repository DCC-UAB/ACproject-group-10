Resultados para Logistic Regression:
Accuracy: 0.9451
Precision: 0.9477
Recall: 0.9968
F1 Score: 0.9716
ROC AUC: 0.9638

Resultados para Random Forest:
Accuracy: 0.9420
Precision: 0.9430
Recall: 0.9989
F1 Score: 0.9701
ROC AUC: 0.9380

Resultados para Naive Bayes (Multinomial):
Accuracy: 0.9430
Precision: 0.9430
Recall: 1.0000
F1 Score: 0.9707
ROC AUC: 0.8603

Resultados para Naive Bayes (Bernoulli):
Accuracy: 0.9186
Precision: 0.9669
Recall: 0.9461
F1 Score: 0.9564
ROC AUC: 0.8949

Resultados para Naive Bayes (Gaussian):
Accuracy: 0.6938
Precision: 0.9446
Recall: 0.7174
F1 Score: 0.8155
ROC AUC: 0.5108

Resultados para Decision Tree:
Accuracy: 0.9390
Precision: 0.9738
Recall: 0.9612
F1 Score: 0.9674
ROC AUC: 0.7663

Resultados para SVM:
Accuracy: 0.9491
Precision: 0.9507
Recall: 0.9978
F1 Score: 0.9737
ROC AUC: 0.9597

Resultados para K-Nearest Neighbors:
Accuracy: 0.9471
Precision: 0.9515
Recall: 0.9946
F1 Score: 0.9726
ROC AUC: 0.8338

Resultados para Gradient Boosting:
Accuracy: 0.9471
Precision: 0.9553
Recall: 0.9903
F1 Score: 0.9725
ROC AUC: 0.9065

Mejores hiperparámetros para LogisticRegression: {'C': 100, 'solver': 'liblinear'}
Mejores hiperparámetros para RandomForestClassifier: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 50}
Mejores hiperparámetros para MultinomialNB: {'alpha': 0.1}
Mejores hiperparámetros para BernoulliNB: {'alpha': 10.0}
Mejores hiperparámetros para DecisionTreeClassifier: {'max_depth': 10, 'min_samples_split': 2}
Mejores hiperparámetros para SVC: {'C': 10, 'kernel': 'linear'}
Mejores hiperparámetros para KNeighborsClassifier: {'n_neighbors': 5, 'weights': 'uniform'}
Mejores hiperparámetros para GradientBoostingClassifier: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}
