{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-27T12:52:23.663264Z",
     "start_time": "2024-11-27T12:52:23.657266Z"
    }
   },
   "source": [
    "#import kagglehub\n",
    "\n",
    "\"\"\"\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"Path to working directory\", \"dataset_name\") # Esto es para descartar el dataset inicial, poner el path en tu ordenador local\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Download latest version\\npath = kagglehub.dataset_download(\"Path to working directory\", \"dataset_name\") # Esto es para descartar el dataset inicial, poner el path en tu ordenador local\\n\\nprint(\"Path to dataset files:\", path)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "fb2cfe75dc75c5b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:52:23.727264Z",
     "start_time": "2024-11-27T12:52:23.690265Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('amazon_reviews.csv')\n",
    "df.head() #Aqui podemos ver el dataset usado, varias columnas innecesarias"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Unnamed: 0  reviewerName  overall  \\\n",
       "0           0           NaN      4.0   \n",
       "1           1          0mie      5.0   \n",
       "2           2           1K3      4.0   \n",
       "3           3           1m2      5.0   \n",
       "4           4  2&amp;1/2Men      5.0   \n",
       "\n",
       "                                          reviewText  reviewTime  day_diff  \\\n",
       "0                                         No issues.  2014-07-23       138   \n",
       "1  Purchased this for my device, it worked as adv...  2013-10-25       409   \n",
       "2  it works as expected. I should have sprung for...  2012-12-23       715   \n",
       "3  This think has worked out great.Had a diff. br...  2013-11-21       382   \n",
       "4  Bought it with Retail Packaging, arrived legit...  2013-07-13       513   \n",
       "\n",
       "   helpful_yes  helpful_no  total_vote  score_pos_neg_diff  \\\n",
       "0            0           0           0                   0   \n",
       "1            0           0           0                   0   \n",
       "2            0           0           0                   0   \n",
       "3            0           0           0                   0   \n",
       "4            0           0           0                   0   \n",
       "\n",
       "   score_average_rating  wilson_lower_bound  \n",
       "0                   0.0                 0.0  \n",
       "1                   0.0                 0.0  \n",
       "2                   0.0                 0.0  \n",
       "3                   0.0                 0.0  \n",
       "4                   0.0                 0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>day_diff</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>total_vote</th>\n",
       "      <th>score_pos_neg_diff</th>\n",
       "      <th>score_average_rating</th>\n",
       "      <th>wilson_lower_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No issues.</td>\n",
       "      <td>2014-07-23</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0mie</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Purchased this for my device, it worked as adv...</td>\n",
       "      <td>2013-10-25</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1K3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>it works as expected. I should have sprung for...</td>\n",
       "      <td>2012-12-23</td>\n",
       "      <td>715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1m2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This think has worked out great.Had a diff. br...</td>\n",
       "      <td>2013-11-21</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2&amp;amp;1/2Men</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Bought it with Retail Packaging, arrived legit...</td>\n",
       "      <td>2013-07-13</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "9dc28ed821d5d9e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:52:23.791265Z",
     "start_time": "2024-11-27T12:52:23.776265Z"
    }
   },
   "source": [
    "#Limpiar el dataset\n",
    "dfSimple = df.drop(columns=['reviewerName', 'reviewTime', 'day_diff', 'helpful_yes', 'helpful_no', 'total_vote', 'score_pos_neg_diff', 'score_average_rating', 'wilson_lower_bound'])\n",
    "dfSimple.head()\n",
    "#De inicio trabajaremos con un dataset masivamente simplificado para poder hacer pruebas, la columna unnamed:0 no se elimina porque es un identificador de la fila y puede ser util mas adelante\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Unnamed: 0  overall                                         reviewText\n",
       "0           0      4.0                                         No issues.\n",
       "1           1      5.0  Purchased this for my device, it worked as adv...\n",
       "2           2      4.0  it works as expected. I should have sprung for...\n",
       "3           3      5.0  This think has worked out great.Had a diff. br...\n",
       "4           4      5.0  Bought it with Retail Packaging, arrived legit..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No issues.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Purchased this for my device, it worked as adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>it works as expected. I should have sprung for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This think has worked out great.Had a diff. br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Bought it with Retail Packaging, arrived legit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "40fbf1f5aa0af698",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:52:23.870264Z",
     "start_time": "2024-11-27T12:52:23.856264Z"
    }
   },
   "source": [
    "#Por ahora, trabajaremos con valores de 0 o 1 en la columna overall para tener un problema simple y poder de inicio identifcar de manera binaria si es positiva o negativa la review. Despues, querremos predecir la nota de la review por el texto con mas exactitud\n",
    "dfSimpleBinary = dfSimple.copy()\n",
    "dfSimpleBinary['overall'] = dfSimpleBinary['overall'].apply(lambda x: 1 if x > 2.5 else 0)\n",
    "dfSimpleBinary['overall'].value_counts()\n",
    "dfSimpleBinary.head(1000)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Unnamed: 0  overall                                         reviewText\n",
       "0             0      4.0                                         No issues.\n",
       "1             1      5.0  Purchased this for my device, it worked as adv...\n",
       "2             2      4.0  it works as expected. I should have sprung for...\n",
       "3             3      5.0  This think has worked out great.Had a diff. br...\n",
       "4             4      5.0  Bought it with Retail Packaging, arrived legit...\n",
       "..          ...      ...                                                ...\n",
       "995         995      5.0  Gave my galaxy S4 plenty of memory and at a go...\n",
       "996         996      5.0  Bought a digital recorder with a memory card s...\n",
       "997         997      5.0  Not much to say, its a memory card but it work...\n",
       "998         998      5.0  32 gig MicroSD card that costs less than a dol...\n",
       "999         999      5.0  I'm a nerd and a hoarder. I waited a year for ...\n",
       "\n",
       "[1000 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No issues.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Purchased this for my device, it worked as adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>it works as expected. I should have sprung for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This think has worked out great.Had a diff. br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Bought it with Retail Packaging, arrived legit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Gave my galaxy S4 plenty of memory and at a go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Bought a digital recorder with a memory card s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Not much to say, its a memory card but it work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32 gig MicroSD card that costs less than a dol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I'm a nerd and a hoarder. I waited a year for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "82b1816b6313d1e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:52:23.964264Z",
     "start_time": "2024-11-27T12:52:23.934265Z"
    }
   },
   "source": [
    "#Guardamos el dataset limpio para no sobreescribirlo accidentalmente, este paso es solo una precaucion. solo falta borrar los nans\n",
    "dfSimpleBinary.dropna(subset=[\"reviewText\"], inplace=True)\n",
    "dfSimpleBinary.to_csv('amazon_reviews_simpleBinary.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "4bb11e23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:52:24.801265Z",
     "start_time": "2024-11-27T12:52:23.996265Z"
    }
   },
   "source": [
    "# Descarregar Natural Language Toolkit (NLTK): Llibreria python per treballar amb text\n",
    "!pip install nltk"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\mique\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\mique\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\mique\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mique\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mique\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mique\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "72896f94fe63f971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:52:24.817265Z",
     "start_time": "2024-11-27T12:52:24.805264Z"
    }
   },
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "3344a866",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:52:24.864265Z",
     "start_time": "2024-11-27T12:52:24.834265Z"
    }
   },
   "source": [
    "# NLTK resources\n",
    "nltk.download('stopwords') #Llista de stopwords + comunes\n",
    "nltk.download('punkt')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mique\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mique\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "54e3a7f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:52:24.895264Z",
     "start_time": "2024-11-27T12:52:24.880264Z"
    }
   },
   "source": [
    "# Cleaning function : punctuation, numbers, URL, convert to lowercase, tokenize, remove stopwords.\n",
    "\"\"\"\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize the text\n",
    "    #words = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in text if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\"\"\"\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Split text into words\n",
    "    words = text.split()\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Join words back into a single string\n",
    "    return ' '.join(words)"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "8f86e814",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:52:25.472226Z",
     "start_time": "2024-11-27T12:52:24.912265Z"
    }
   },
   "source": [
    "# Create a new DataFrame with cleaned reviewText and the overall column\n",
    "dfSimpleBinaryCleaned = pd.DataFrame()\n",
    "dfSimpleBinaryCleaned['reviewText'] = dfSimpleBinary['reviewText'].apply(clean_text)  # Apply the cleaning function\n",
    "dfSimpleBinaryCleaned['overall'] = dfSimpleBinary['overall']  # Include the overall column\n",
    "\n",
    "print(dfSimpleBinaryCleaned.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          reviewText  overall\n",
      "0                                             issues      4.0\n",
      "1  purchased device worked advertised never much ...      5.0\n",
      "2  works expected sprung higher capacity think ma...      4.0\n",
      "3  think worked greathad diff bran gb card went s...      5.0\n",
      "4  bought retail packaging arrived legit orange e...      5.0\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "4ecb2a6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:52:25.504225Z",
     "start_time": "2024-11-27T12:52:25.489226Z"
    }
   },
   "source": [
    "# Save the cleaned dataset \n",
    "dfSimpleBinaryCleaned.to_csv('amazon_reviews_simpleBinaryCleaned.csv', index=False)\n",
    "\n",
    "print(\"Cleaned dataset saved as 'amazon_reviews_simpleBinaryCleaned.csv'\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved as 'amazon_reviews_simpleBinaryCleaned.csv'\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "38ef9d35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:52:25.584226Z",
     "start_time": "2024-11-27T12:52:25.521226Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Apply TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Limit to 5000 features for simplicity\n",
    "X = tfidf.fit_transform(dfSimpleBinaryCleaned['reviewText'])  \n",
    "\n",
    "# y = Etiqueta\n",
    "y = dfSimpleBinaryCleaned['overall']  "
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "e570122c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:52:25.630225Z",
     "start_time": "2024-11-27T12:52:25.616228Z"
    }
   },
   "source": [
    "# Això nomes per ara per visualitzar el resultat despres de TF-IDF. X : sparse matrix (4914,5000), sparse matrix es representa per coordenades ja que en gran part està buida\n",
    "print(X)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1811)\t1.0\n",
      "  (1, 2960)\t0.2390691997557985\n",
      "  (1, 901)\t0.2500956641441643\n",
      "  (1, 4814)\t0.22041352975002462\n",
      "  (1, 65)\t0.3079511880305262\n",
      "  (1, 2283)\t0.23746924750824877\n",
      "  (1, 2235)\t0.22880268690799568\n",
      "  (1, 2527)\t0.15894729456975054\n",
      "  (1, 2124)\t0.16342700659146378\n",
      "  (1, 3614)\t0.2634346235438177\n",
      "  (1, 980)\t0.3515768967137597\n",
      "  (1, 2004)\t0.25280027831644336\n",
      "  (1, 4010)\t0.3197017006470681\n",
      "  (1, 371)\t0.4658817477827855\n",
      "  (2, 4826)\t0.10167611425771444\n",
      "  (2, 1187)\t0.21026831614423724\n",
      "  (2, 3834)\t0.4017209024878068\n",
      "  (2, 1617)\t0.26622741443620596\n",
      "  (2, 460)\t0.18410928375398103\n",
      "  (2, 4235)\t0.20417737012953208\n",
      "  (2, 2031)\t0.22707996152754703\n",
      "  (2, 320)\t0.22808251479726946\n",
      "  (2, 1032)\t0.32830745830827224\n",
      "  (2, 4490)\t0.2923424981405928\n",
      "  (2, 2453)\t0.37010345303225173\n",
      "  :\t:\n",
      "  (4912, 3723)\t0.28806210890236555\n",
      "  (4912, 1308)\t0.4263389161515658\n",
      "  (4912, 3453)\t0.3055102773347161\n",
      "  (4912, 125)\t0.42527201043850527\n",
      "  (4912, 1495)\t0.3158426707913027\n",
      "  (4913, 1435)\t0.12001865352878269\n",
      "  (4913, 469)\t0.08437957493415665\n",
      "  (4913, 1830)\t0.17241066293745294\n",
      "  (4913, 1941)\t0.1605960734865905\n",
      "  (4913, 2761)\t0.13526336827535024\n",
      "  (4913, 3476)\t0.1305370822597514\n",
      "  (4913, 1490)\t0.1351408230779796\n",
      "  (4913, 3723)\t0.16543682237108262\n",
      "  (4913, 4309)\t0.18106842770795104\n",
      "  (4913, 3186)\t0.16793354503937788\n",
      "  (4913, 1582)\t0.3165828487550289\n",
      "  (4913, 1244)\t0.17134947380143642\n",
      "  (4913, 3781)\t0.19126394528883536\n",
      "  (4913, 2145)\t0.15976659846407368\n",
      "  (4913, 2312)\t0.2850855019302672\n",
      "  (4913, 253)\t0.22071682877236967\n",
      "  (4913, 4234)\t0.24015669759878808\n",
      "  (4913, 4653)\t0.2599726839400095\n",
      "  (4913, 765)\t0.39895252665976416\n",
      "  (4913, 3911)\t0.4182065391329697\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:52:25.898225Z",
     "start_time": "2024-11-27T12:52:25.647226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "# Entrenar modelos\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100)\n",
    "}\n",
    "\n",
    "# Diccionario para almacenar los resultados\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    # Predecir en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    # Evaluar el rendimiento\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # Guardar los resultados\n",
    "    results[model_name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"FPR\": fpr,\n",
    "        \"TPR\": tpr\n",
    "    }\n",
    "\n",
    "# Imprimir los resultados\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Resultados para {model_name}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            continue\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Crear el gráfico comparativo de la curva ROC\n",
    "plt.figure(figsize=(10, 5))\n",
    "for model_name, metrics in results.items():\n",
    "    plt.plot(metrics[\"FPR\"], metrics[\"TPR\"], label=f'{model_name} (AUC = {metrics[\"ROC AUC\"]:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Curva ROC Comparativa')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "id": "93e3ebf8a587c7ab",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 27\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# Evaluar el rendimiento\u001B[39;00m\n\u001B[0;32m     26\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m accuracy_score(y_test, y_pred)\n\u001B[1;32m---> 27\u001B[0m precision \u001B[38;5;241m=\u001B[39m \u001B[43mprecision_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m recall \u001B[38;5;241m=\u001B[39m recall_score(y_test, y_pred)\n\u001B[0;32m     29\u001B[0m f1 \u001B[38;5;241m=\u001B[39m f1_score(y_test, y_pred)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2190\u001B[0m, in \u001B[0;36mprecision_score\u001B[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m   2023\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[0;32m   2024\u001B[0m     {\n\u001B[0;32m   2025\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2050\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   2051\u001B[0m ):\n\u001B[0;32m   2052\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the precision.\u001B[39;00m\n\u001B[0;32m   2053\u001B[0m \n\u001B[0;32m   2054\u001B[0m \u001B[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2188\u001B[0m \u001B[38;5;124;03m    array([0.5, 1. , 1. ])\u001B[39;00m\n\u001B[0;32m   2189\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 2190\u001B[0m     p, _, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43mprecision_recall_fscore_support\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2191\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2192\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2193\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2194\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2195\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2196\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwarn_for\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprecision\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2197\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2198\u001B[0m \u001B[43m        \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzero_division\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2199\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2200\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m p\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    184\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[1;32m--> 186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    188\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[0;32m    190\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1775\u001B[0m, in \u001B[0;36mprecision_recall_fscore_support\u001B[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m   1612\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001B[39;00m\n\u001B[0;32m   1613\u001B[0m \n\u001B[0;32m   1614\u001B[0m \u001B[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1772\u001B[0m \u001B[38;5;124;03m array([2, 2, 2]))\u001B[39;00m\n\u001B[0;32m   1773\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1774\u001B[0m _check_zero_division(zero_division)\n\u001B[1;32m-> 1775\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[43m_check_set_wise_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1777\u001B[0m \u001B[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001B[39;00m\n\u001B[0;32m   1778\u001B[0m samplewise \u001B[38;5;241m=\u001B[39m average \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1564\u001B[0m, in \u001B[0;36m_check_set_wise_labels\u001B[1;34m(y_true, y_pred, average, labels, pos_label)\u001B[0m\n\u001B[0;32m   1562\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1563\u001B[0m             average_options\u001B[38;5;241m.\u001B[39mremove(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1564\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1565\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTarget is \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m but average=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Please \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1566\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchoose another average setting, one of \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (y_type, average_options)\n\u001B[0;32m   1567\u001B[0m         )\n\u001B[0;32m   1568\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m pos_label \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1569\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1570\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNote that pos_label (set to \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m) is ignored when \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1571\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage != \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (got \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m). You may use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1574\u001B[0m         \u001B[38;5;167;01mUserWarning\u001B[39;00m,\n\u001B[0;32m   1575\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:52:25.900227Z",
     "start_time": "2024-11-27T12:48:50.713112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Definir las métricas de evaluación\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "# Validación cruzada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluar cada modelo con validación cruzada\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluando {model_name} con validación cruzada:\")\n",
    "    for metric_name, metric in scoring.items():\n",
    "        scores = cross_val_score(model, X, y, cv=cv, scoring=metric)\n",
    "        print(f\"{metric_name}: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n",
    "    print(\"\\n\")"
   ],
   "id": "8e57e1e5c4ec1f98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando Logistic Regression con validación cruzada:\n",
      "accuracy: 0.9385 (+/- 0.0010)\n",
      "precision: 0.9395 (+/- 0.0013)\n",
      "recall: 0.9985 (+/- 0.0009)\n",
      "f1: 0.9681 (+/- 0.0005)\n",
      "roc_auc: 0.9602 (+/- 0.0084)\n",
      "\n",
      "\n",
      "Evaluando Random Forest con validación cruzada:\n",
      "accuracy: 0.9357 (+/- 0.0018)\n",
      "precision: 0.9358 (+/- 0.0013)\n",
      "recall: 0.9993 (+/- 0.0005)\n",
      "f1: 0.9666 (+/- 0.0004)\n",
      "roc_auc: 0.9432 (+/- 0.0103)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f2f11b877c514aa3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
